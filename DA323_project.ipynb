{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff9f6519",
   "metadata": {},
   "source": [
    "# Zero Shot Text to Image Generation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e3b35",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- About the Paper  \n",
    "- Motivation  \n",
    "- Previous Approaches  \n",
    "- Method  \n",
    "- Datasets  \n",
    "- Significance and Results  \n",
    "- Future Impact  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fad22d",
   "metadata": {},
   "source": [
    "# About the Paper\n",
    "\n",
    "**Paper Title:**  \n",
    "*Zero-Shot Text-to-Image Generation*  \n",
    "\n",
    "**Authors:**  \n",
    "Aditya Ramesh, Mikhail Pavlov, Gabriel Goh, Scott Gray,  \n",
    "Chelsea Voss, Alec Radford, Mark Chen, Ilya Sutskever (OpenAI)  \n",
    "\n",
    "**Published:**  \n",
    "arXiv preprint: [https://arxiv.org/abs/2102.12092](https://arxiv.org/abs/2102.12092)  \n",
    "Date: February 2021  \n",
    "\n",
    "**Core Contribution:**  \n",
    "A scalable, autoregressive transformer-based model that treats text and image tokens as a single sequence.  \n",
    "Capable of generating realistic images from text prompts **without any task-specific fine-tuning**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9fad52",
   "metadata": {},
   "source": [
    "## Motivation for this Paper\n",
    "\n",
    "Earlier models like **GANs** and **VAEs** struggle with generalization — that is, they perform poorly on unseen data.\n",
    "\n",
    "Major issues with GANs include:\n",
    "- **Mode collapse**  \n",
    "  The GAN ends up producing data very similar to only a few types (the “modes”), which adversely affects the variety of obtained multi-modal data.\n",
    "  \n",
    "- **Nonconvergence and instability**  \n",
    "  This can arise due to:\n",
    "  - Inappropriate design of network architecture  \n",
    "  - Poor choice of objective function  \n",
    "  - Suboptimal optimization algorithms\n",
    "\n",
    "Training instability is a critical problem. For example, if the discriminator can easily distinguish between fake and real images, its gradient vanishes —\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01657ce",
   "metadata": {},
   "source": [
    "![Alt text](Desktop/mode_collapse.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e2687b",
   "metadata": {},
   "source": [
    "\n",
    "Traditionally, **text-to-image synthesis** has been approached by improving modeling assumptions for training on a fixed dataset.\n",
    "\n",
    "These approaches often rely on:\n",
    "- Complex architectures  \n",
    "- Auxiliary losses  \n",
    "- Object part labels  \n",
    "- Dataset-specific design choices  \n",
    "\n",
    "Such methods can **hurt generalization**, making them less effective on unseen prompts or domains.\n",
    "\n",
    "---\n",
    "\n",
    "To counter these limitations, the authors propose a **simple and scalable approach**:\n",
    "- Use an **autoregressive transformer**  \n",
    "- Model **text and image tokens as a single stream of data**  \n",
    "\n",
    "With enough data, this method proves **competitive with task-specific models** when evaluated in a **zero-shot** setting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9667b0d",
   "metadata": {},
   "source": [
    "## Generating Images from Captions with Attention\n",
    "\n",
    "In **Mansimov et al., 2015**, the authors extended the **Deep Recurrent Attention Writer (DRAW)** technique to train a model that:\n",
    "\n",
    "- Iteratively draws patches on a canvas  \n",
    "- Attends to relevant words in the text description at each step  \n",
    "\n",
    "### Key Mechanism:\n",
    "- The current hidden state for image generation is computed using:\n",
    "  - The **previous hidden state**, and  \n",
    "  - An **alignment score** between:\n",
    "    - The hidden states from the text  \n",
    "    - The previous image hidden state  \n",
    "\n",
    "- This current hidden state is then used to **generate the image at the current iteration**\n",
    "\n",
    "This was one of the **first deep learning-based approaches** for image synthesis from natural language descriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1de365",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
