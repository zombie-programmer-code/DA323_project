{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:39:30.564401Z","iopub.execute_input":"2025-05-06T06:39:30.565039Z","iopub.status.idle":"2025-05-06T06:39:34.200638Z","shell.execute_reply.started":"2025-05-06T06:39:30.565014Z","shell.execute_reply":"2025-05-06T06:39:34.199840Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class VQVAE(nn.Module):\n    def __init__(self, num_embeddings=512, embedding_dim=64):\n        super().__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, 4, 2, 1), nn.ReLU(),\n            nn.Conv2d(64, 128, 4, 2, 1), nn.ReLU(),\n            nn.Conv2d(128, embedding_dim, 1)\n        )\n        self.codebook = nn.Embedding(num_embeddings, embedding_dim)\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(embedding_dim, 128, 4, 2, 1), nn.ReLU(),\n            nn.ConvTranspose2d(128, 64, 4, 2, 1), nn.ReLU(),\n            nn.Conv2d(64, 3, 1), nn.Tanh()\n        )\n\n    def forward(self, x):\n        z_e = self.encoder(x)  # [B, D, H, W]\n        flat_z = z_e.permute(0, 2, 3, 1).contiguous().view(-1, z_e.size(1))\n\n        # Quantization\n        dists = (flat_z.unsqueeze(1) - self.codebook.weight).pow(2).sum(-1)\n        indices = dists.argmin(1)\n        z_q = self.codebook(indices).view(z_e.shape).permute(0, 2, 3, 1).contiguous()\n        z_q = z_q.permute(0, 3, 1, 2)\n\n        # Straight-through estimator\n        z_q_st = z_e + (z_q - z_e).detach()\n\n        x_recon = self.decoder(z_q_st)\n        return x_recon, z_e, z_q\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:39:34.201865Z","iopub.execute_input":"2025-05-06T06:39:34.202209Z","iopub.status.idle":"2025-05-06T06:39:34.209581Z","shell.execute_reply.started":"2025-05-06T06:39:34.202190Z","shell.execute_reply":"2025-05-06T06:39:34.208860Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def vqvae_loss(x, x_recon, z_e, z_q, beta=0.25):\n    recon_loss = F.mse_loss(x_recon, x)\n    commit_loss = F.mse_loss(z_e.detach(), z_q)\n    codebook_loss = F.mse_loss(z_e, z_q.detach())\n    return recon_loss + codebook_loss + beta * commit_loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:39:34.210287Z","iopub.execute_input":"2025-05-06T06:39:34.210533Z","iopub.status.idle":"2025-05-06T06:39:34.247705Z","shell.execute_reply.started":"2025-05-06T06:39:34.210518Z","shell.execute_reply":"2025-05-06T06:39:34.246922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchvision.datasets import CIFAR10\nfrom torchvision.transforms import ToTensor, Compose, Normalize, Resize\n\ntransform = Compose([Resize(32), ToTensor(), Normalize([0.5]*3, [0.5]*3)])\ntrainset = CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:39:34.249187Z","iopub.execute_input":"2025-05-06T06:39:34.249384Z","iopub.status.idle":"2025-05-06T06:39:42.483144Z","shell.execute_reply.started":"2025-05-06T06:39:34.249368Z","shell.execute_reply":"2025-05-06T06:39:42.482509Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = \"cuda\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:39:42.483915Z","iopub.execute_input":"2025-05-06T06:39:42.484262Z","iopub.status.idle":"2025-05-06T06:39:42.488087Z","shell.execute_reply.started":"2025-05-06T06:39:42.484244Z","shell.execute_reply":"2025-05-06T06:39:42.487402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 50","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\nmodel = VQVAE().to(device)\nopt = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nfor epoch in range(num_epochs):\n    epoch_loss = 0\n    pbar = tqdm(trainloader, desc=f\"Epoch {epoch+1}\", leave=False)\n\n    for x, _ in pbar:\n        x = x.to(device)\n        x_recon, z_e, z_q = model(x)\n        loss = vqvae_loss(x, x_recon, z_e, z_q)\n\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n\n        epoch_loss += loss.item()\n        pbar.set_postfix(loss=loss.item())\n\n    print(f\"Epoch {epoch+1}: avg_loss = {epoch_loss / len(trainloader):.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:39:42.488746Z","iopub.execute_input":"2025-05-06T06:39:42.489023Z","iopub.status.idle":"2025-05-06T06:55:20.090461Z","shell.execute_reply.started":"2025-05-06T06:39:42.488980Z","shell.execute_reply":"2025-05-06T06:55:20.089729Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nx, _ = next(iter(trainloader))\nx = x.to(device)\n\nwith torch.no_grad():\n    x_recon, _, _ = model(x)\n\ndef show_images(orig, recon, num=6):\n    orig = orig[:num].cpu()\n    recon = recon[:num].cpu()\n\n    plt.figure(figsize=(num * 2, 4))\n    for i in range(num):\n        # Original\n        plt.subplot(2, num, i + 1)\n        plt.imshow(orig[i].permute(1, 2, 0).clamp(0, 1))\n        plt.axis('off')\n        if i == 0: plt.title(\"Original\")\n\n        # Reconstructed\n        plt.subplot(2, num, num + i + 1)\n        plt.imshow(recon[i].permute(1, 2, 0).clamp(0, 1))\n        plt.axis('off')\n        if i == 0: plt.title(\"Reconstructed\")\n\n    plt.tight_layout()\n    plt.show()\n\nshow_images(x, x_recon)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:55:20.091359Z","iopub.execute_input":"2025-05-06T06:55:20.091569Z","iopub.status.idle":"2025-05-06T06:55:20.547585Z","shell.execute_reply.started":"2025-05-06T06:55:20.091550Z","shell.execute_reply":"2025-05-06T06:55:20.546681Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with torch.no_grad():\n    z_e = model.encoder(x)  # shape [B, D, H, W]\n    z_flat = z_e.permute(0, 2, 3, 1).reshape(-1, model.codebook.embedding_dim)\n    dists = torch.cdist(z_flat, model.codebook.weight)\n    tokens = dists.argmin(dim=1).reshape(x.size(0), z_e.size(2), z_e.size(3))  # [B, H, W]\n    token_seqs = tokens.view(x.size(0), -1)  # Flatten for transformer\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:55:20.548309Z","iopub.execute_input":"2025-05-06T06:55:20.548542Z","iopub.status.idle":"2025-05-06T06:55:20.617408Z","shell.execute_reply.started":"2025-05-06T06:55:20.548527Z","shell.execute_reply":"2025-05-06T06:55:20.616891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef visualize_token_grid(tokens, num_images=6):\n    plt.figure(figsize=(num_images * 2, 2.5))\n    for i in range(num_images):\n        grid = tokens[i].cpu().numpy()  # shape [H, W]\n        plt.subplot(1, num_images, i + 1)\n        plt.imshow(grid, cmap='viridis')  # or 'plasma', 'gray'\n        plt.title(f\"Token Grid {i+1}\")\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\nvisualize_token_grid(tokens, num_images=6)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:55:20.618121Z","iopub.execute_input":"2025-05-06T06:55:20.618337Z","iopub.status.idle":"2025-05-06T06:55:21.071391Z","shell.execute_reply.started":"2025-05-06T06:55:20.618320Z","shell.execute_reply":"2025-05-06T06:55:21.070672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_image_and_tokens(imgs, tokens, index=0):\n    img = imgs[index].cpu().permute(1, 2, 0)  # [C, H, W] -> [H, W, C]\n    img = (img * 0.5 + 0.5).clamp(0, 1)        # unnormalize\n\n    token_grid = tokens[index].cpu().numpy()\n\n    plt.figure(figsize=(6, 3))\n    plt.subplot(1, 2, 1)\n    plt.imshow(img)\n    plt.title(\"Original Image\")\n    plt.axis('off')\n\n    plt.subplot(1, 2, 2)\n    plt.imshow(token_grid, cmap='viridis')\n    plt.title(\"Token IDs\")\n    plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\nshow_image_and_tokens(x, tokens, index=0)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-06T06:55:21.073668Z","iopub.execute_input":"2025-05-06T06:55:21.073888Z","iopub.status.idle":"2025-05-06T06:55:21.220216Z","shell.execute_reply.started":"2025-05-06T06:55:21.073871Z","shell.execute_reply":"2025-05-06T06:55:21.219599Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}